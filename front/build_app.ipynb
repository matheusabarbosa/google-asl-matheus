{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7fcfe6-f8c8-46e2-b5d1-1c8354697664",
   "metadata": {},
   "source": [
    "# Deploying a Streamlit Chatbot App on Google Cloud Run\n",
    "\n",
    "This guide provides you with the scaffold and steps to build a simple chatbot application with Gemini using Streamlit.\n",
    "\n",
    "\n",
    "### What is Streamlit?\n",
    "[Streamlit](https://streamlit.io/) is an open-source Python library that's become the go-to tool for quickly creating interactive web applications, especially for data science and machine learning projects.  Streamlit's intuitive design makes it easy to build powerful apps with minimal code.\n",
    "\n",
    "Check out the amazing examples in the [Streamlit Gallery](https://streamlit.io/gallery) to see the wide range of applications you can create. From data dashboards and visualizations to machine learning demos and interactive tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3a625-c626-4fad-b6b0-794f3a937e27",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll setup a few variables to interact with Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ad47080-ad70-4a5d-a1c3-72a5ea72b841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:28.250701Z",
     "iopub.status.busy": "2025-12-09T14:15:28.249729Z",
     "iopub.status.idle": "2025-12-09T14:15:29.137000Z",
     "shell.execute_reply": "2025-12-09T14:15:29.135467Z",
     "shell.execute_reply.started": "2025-12-09T14:15:28.250655Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8b040-a64a-4925-bd96-123185f4c66f",
   "metadata": {},
   "source": [
    "---\n",
    "## Build a streamlit application\n",
    "\n",
    "The application code is written in [app.py](./app.py). Here let's check important concepts in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d32d88-ae75-4b73-9856-f15aa26f7cfc",
   "metadata": {},
   "source": [
    "### Add text elements\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "```python\n",
    "st.set_page_config(page_title=\"Chat with Gemini\", page_icon=\"♊\")\n",
    "\n",
    "st.title(\"Chat with Gemini\")\n",
    "\n",
    "st.markdown(\"Welcome to this simple web application to chat with Gemini\")\n",
    "```\n",
    "</div>\n",
    "\n",
    "Streamlit eventually renders a web page, but we can simply use Python modules to define the visual and behavior of it.\n",
    "\n",
    "We'll start by configuring some metadata for our app.\n",
    "\n",
    "- [`st.set_page_config`](https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config) lets us customize aspects like the page title and favicon (the little icon that appears in your browser tab).\n",
    "\n",
    "Streamlit provides a variety of ways to display text content:\n",
    "\n",
    "- [`st.title`](https://docs.streamlit.io/develop/api-reference/text/st.title) is used to add a main heading to our page.\n",
    "- You can also use [`st.header`](https://docs.streamlit.io/develop/api-reference/text/st.header) and [`st.subheader`](https://docs.streamlit.io/develop/api-reference/text/st.subheader) for smaller headings.\n",
    "- [`st.text`](https://docs.streamlit.io/develop/api-reference/text/st.text) is for displaying plain text.\n",
    "- [`st.markdown`](https://docs.streamlit.io/develop/api-reference/text/st.markdown) lets you add formatted text using Markdown syntax.\n",
    "For more options, you can check the Streamlit documentation for [other text elements](https://docs.streamlit.io/develop/api-reference/text).\n",
    "\n",
    "Streamlit also offer a \"swiss-army knife\" command called [`st.write`](https://docs.streamlit.io/develop/api-reference/write-magic/st.write). It can handle many types of content, including text, DataFrames (tables of data), Matplotlib plots, and even Keras machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227b203-99f0-4113-bbc7-1cb091f572c8",
   "metadata": {},
   "source": [
    "And let's setup some variables.\n",
    "\n",
    "The environment variables (`GCP_PROJECT` and `GCP_REGION`) can be set later when we deploy the app to Cloud Run.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "```python\n",
    "PROJECT_ID = os.environ.get(\"GCP_PROJECT\")\n",
    "LOCATION = os.environ.get(\"GCP_REGION\")\n",
    "\n",
    "client = genai.Client(project=PROJECT_ID, vertexai=True, location=LOCATION)\n",
    "\n",
    "if \"gemini_model\" not in st.session_state:\n",
    "    st.session_state[\"gemini_model\"] = \"gemini-2.0-flash\"\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fd845-f835-491b-874f-584e58f52f19",
   "metadata": {},
   "source": [
    "### Setup session state\n",
    "Remember, Streamlit reruns the code from the top to the bottom every time an event happens.<br>\n",
    "[Session State](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state) is a way to share variables between these reruns for each user session. We can save values in a key-value format in `st.session_state`.\n",
    "\n",
    "Since this is a chatbot app, we have to keep chat histories. Let's make a `\"messages\"` key and save histories as a list.<br>\n",
    "If the `\"messages\"` key is not present in the session state (when you open the page first), we initialize the list. If the key is already created, we iterate the list and show each message on the page.\n",
    "\n",
    "For chatbot apps, we can use the [`st.chat_message`](https://docs.streamlit.io/develop/api-reference/chat/st.chat_message) container to show each message on the page.<br>\n",
    "We can use `with` notation to add elements to the returned container or simply call methods directly on the returned object.\n",
    "E.g.,\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "```python\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(name=message[\"role\"], avatar=message[\"avatar\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "```\n",
    "or\n",
    "```python\n",
    "for message in st.session_state.messages:\n",
    "    message = st.chat_message(name=message[\"role\"], avatar=message[\"avatar\"])\n",
    "    message.markdown(message[\"content\"])\n",
    "```\n",
    "</div>\n",
    "\n",
    "The chat_message takes two arguments:\n",
    "- `name`: The name of the message author. It can be \"human\"/\"user\" or \"ai\"/\"assistant\" to enable preset styling and avatars.\n",
    "- `avatar`: The avatar shown next to the message. \n",
    "  - You can specify images supported by [st.image](https://docs.streamlit.io/develop/api-reference/media/st.image).\n",
    "  - Some emoji formats are supported. See [the document](https://docs.streamlit.io/develop/api-reference/chat/st.chat_message) for the details.\n",
    "  - If it is None (default), the icon will be determined by name (\"user\"/\"human\" or \"ai\"/\"assistant\")\n",
    "  \n",
    "We pass these arguments from each message dictionary we'll add later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81422c28-68cc-4a9a-a593-9700366e0276",
   "metadata": {},
   "source": [
    "### Helper Functions for conversations\n",
    "Let's define the helper functions we'll use later.\n",
    "\n",
    "The `generate_response` function starts a chat with Gemini using a history in the session.\n",
    "\n",
    "The `stream` function will be used later to write the Gemini response in a stream for a more interactive user experience, instead of writing all the responses simultaneously.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "```python\n",
    "def generate_response(input_text):\n",
    "    chat = client.chats.create(\n",
    "        model=st.session_state[\"gemini_model\"],\n",
    "        history=[\n",
    "            Content(role=message[\"role\"], parts=[Part.from_text(text=message[\"content\"])])\n",
    "            for message in st.session_state.messages[:-1]\n",
    "        ]\n",
    "    )\n",
    "    return chat.send_message(input_text)\n",
    "\n",
    "\n",
    "def stream(text):\n",
    "    for word in text.split(\" \"):\n",
    "        yield word + \" \"\n",
    "        time.sleep(0.02)\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4bd06-5fe9-4f2b-bbb7-968a646bbf91",
   "metadata": {},
   "source": [
    "### Define the chat iteration\n",
    "\n",
    "Let's define the iteration of chat interactions, which has these steps:\n",
    "1. Show the user input on the page. We use `st.chat_message` as `\"user\"` name and `st.write` to add a message.\n",
    "2. Add the user input to the message history in the session state.\n",
    "3. Call Gemini and write the response. Here, we use `\"assistant\"` as the name and specify the Gemini icon as the avatar. Also, use `st.write_stream` with the `stream` function to show the response in a stream.\n",
    "4. Add the Gemini response to the message history in the session state.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "```python\n",
    "if prompt := st.chat_input(\"Write a promt\"):\n",
    "    # 1. Write the user message\n",
    "    with st.chat_message(name=\"user\", avatar=None):\n",
    "        st.write(prompt)\n",
    "    # 2. Add user message to message history\n",
    "    st.session_state.messages.append(\n",
    "        {\"role\": \"user\", \"content\": prompt, \"avatar\": None}\n",
    "    )\n",
    "\n",
    "    # 3. Call Gemini and write the response\n",
    "    with st.chat_message(name=\"assistant\", avatar=\"assets/gemini-icon.png\"):\n",
    "        response = generate_response(prompt)\n",
    "        st.write_stream(stream(response.text))\n",
    "    # 4. Add Gemini response to message history\n",
    "    st.session_state.messages.append(\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"content\": response.text,\n",
    "            \"avatar\": \"assets/gemini-icon.png\",\n",
    "        }\n",
    "    )\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c0808-5299-4527-9df5-1492beb7d9d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Deploying the App on Cloud Run\n",
    "Our Streamlit application is ready! Let's deploy it to Google Cloud Run, a serverless platform designed to run containerized applications seamlessly.\n",
    "\n",
    "### Defining Dockerfile and Dependencies\n",
    "To containerize our app for Cloud Run, we define `requirements.txt` and `Dockerfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dda5418e-937e-4c34-9996-3e96f51bf332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:29.140197Z",
     "iopub.status.busy": "2025-12-09T14:15:29.139251Z",
     "iopub.status.idle": "2025-12-09T14:15:29.148909Z",
     "shell.execute_reply": "2025-12-09T14:15:29.147275Z",
     "shell.execute_reply.started": "2025-12-09T14:15:29.140106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "streamlit==1.44.1\n",
    "google-cloud-aiplatform==1.85.0\n",
    "google-genai==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e8c4c8a7-7f63-450d-8301-4fa4af53ca2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:29.151628Z",
     "iopub.status.busy": "2025-12-09T14:15:29.151153Z",
     "iopub.status.idle": "2025-12-09T14:15:29.165797Z",
     "shell.execute_reply": "2025-12-09T14:15:29.164023Z",
     "shell.execute_reply.started": "2025-12-09T14:15:29.151561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.10.14\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt /app\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY assets /app/assets\n",
    "COPY app.py /app\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "CMD streamlit run --server.port 8080 --server.enableCORS false app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d25e8-7171-47b5-ab9e-5053fad20b6a",
   "metadata": {},
   "source": [
    "**Note: We've split the `COPY` command into multiple lines, each copying different files. Although this is not required, this is a crucial optimization for Docker's caching mechanism.<br> If you make changes only to app.py, the next time you build the image, Docker will reuse the cached layers for the dependency installation and other files, speeding up the build process significantly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e22c5-e73b-42d3-97c9-bed2011b2812",
   "metadata": {},
   "source": [
    "### Building and Pushing the Container to Artifact Registry\n",
    "Now that we have our `Dockerfile`, we can build the Docker image of our Streamlit app and push it to Google Cloud's Artifact Registry. \n",
    "Artifact Registry offers a secure and scalable way to store your container images.\n",
    "\n",
    "First, we'll create a new repository in Artifact Registry to house our container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "974e950b-396a-4fd5-83c2-4ec400d0611f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:29.173306Z",
     "iopub.status.busy": "2025-12-09T14:15:29.168743Z",
     "iopub.status.idle": "2025-12-09T14:15:29.187462Z",
     "shell.execute_reply": "2025-12-09T14:15:29.185926Z",
     "shell.execute_reply.started": "2025-12-09T14:15:29.173178Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STREAMLIT_ARTIFACT_REG_REPO = \"gemini-chatbot-app\"\n",
    "os.environ[\"STREAMLIT_ARTIFACT_REG_REPO\"] = STREAMLIT_ARTIFACT_REG_REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab85dcad-4dc1-4fb2-926c-bf19826d57e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:29.189250Z",
     "iopub.status.busy": "2025-12-09T14:15:29.188641Z",
     "iopub.status.idle": "2025-12-09T14:15:30.608735Z",
     "shell.execute_reply": "2025-12-09T14:15:30.607621Z",
     "shell.execute_reply.started": "2025-12-09T14:15:29.189117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gcloud artifacts repositories describe $STREAMLIT_ARTIFACT_REG_REPO \\\n",
    "       --location=$REGION > /dev/null 2>&1; then\n",
    "    gcloud artifacts repositories create $STREAMLIT_ARTIFACT_REG_REPO \\\n",
    "        --project=$PROJECT --location=$REGION --repository-format=docker\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a7418-ad96-420f-bfdc-06f83a142df5",
   "metadata": {},
   "source": [
    "### Defining cloudbuild.yaml for Cloud Build\n",
    "We'll use Google Cloud Build to automate the process of building our Docker image and pushing it to Artifact Registry. \n",
    "\n",
    "Cloud Build is a serverless CI/CD platform that lets you define build steps in a configuration file called cloudbuild.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ec83318-31ac-4d2b-b4c2-10028b2b9c2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:30.610940Z",
     "iopub.status.busy": "2025-12-09T14:15:30.610318Z",
     "iopub.status.idle": "2025-12-09T14:15:30.616731Z",
     "shell.execute_reply": "2025-12-09T14:15:30.615430Z",
     "shell.execute_reply.started": "2025-12-09T14:15:30.610884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTAINER_PATH = (\n",
    "    f\"us-central1-docker.pkg.dev/{PROJECT}/{STREAMLIT_ARTIFACT_REG_REPO}/app\"\n",
    ")\n",
    "os.environ[\"CONTAINER_PATH\"] = CONTAINER_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67075a-0864-429b-8be8-0fdf052a70c9",
   "metadata": {},
   "source": [
    "Here's a cloudbuild.yaml file that incorporates caching to make our builds faster:\n",
    "\n",
    "1. **Pull Existing Image**: The first step attempts to pull the latest version of your Docker image from Artifact Registry. Here we use `bash -c` command as the entrypoint so that the job can ignore and proceed even if this step fails in the first run.\n",
    "2. **Build with Caching**: The second step builds the new image. `--cache-from` flag tells Docker to use the layers from the pulled image as a cache, speeding up the build if there are no changes to those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82177b1a-7d4f-4a4e-9fb6-409a7c868414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:30.618588Z",
     "iopub.status.busy": "2025-12-09T14:15:30.618183Z",
     "iopub.status.idle": "2025-12-09T14:15:30.627457Z",
     "shell.execute_reply": "2025-12-09T14:15:30.626254Z",
     "shell.execute_reply.started": "2025-12-09T14:15:30.618538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cloudbuild.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cloudbuild.yaml\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  entrypoint: 'bash'\n",
    "  args: ['-c', 'docker pull ${_CONTAINER_PATH}:latest || exit 0']\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [\n",
    "            'build',\n",
    "            '-t', '${_CONTAINER_PATH}:latest',\n",
    "            '--cache-from', '${_CONTAINER_PATH}:latest',\n",
    "            '.'\n",
    "        ]\n",
    "images: ['${_CONTAINER_PATH}:latest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c4542-ec7e-497a-b3b4-4d7dabf68561",
   "metadata": {},
   "source": [
    "### Building the Container Image\n",
    "\n",
    "With our cloudbuild.yaml file defined, we can now instruct Cloud Build to construct our Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b97b54f0-8e7a-4a5c-8fb0-fb684e944676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:15:30.629297Z",
     "iopub.status.busy": "2025-12-09T14:15:30.628652Z",
     "iopub.status.idle": "2025-12-09T14:16:25.013877Z",
     "shell.execute_reply": "2025-12-09T14:16:25.011948Z",
     "shell.execute_reply.started": "2025-12-09T14:15:30.629250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary archive of 14 file(s) totalling 122.0 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://qwiklabs-asl-03-4fafb71c2045_cloudbuild/source/1765289731.607243-9a47ab0d40b14510ba3d1ed1a907cefe.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-asl-03-4fafb71c2045/locations/us-central1/builds/7c130f52-c7c9-4b67-b07c-bab24c4158c5].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/7c130f52-c7c9-4b67-b07c-bab24c4158c5?project=949926840523 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"7c130f52-c7c9-4b67-b07c-bab24c4158c5\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-asl-03-4fafb71c2045_cloudbuild/source/1765289731.607243-9a47ab0d40b14510ba3d1ed1a907cefe.tgz#1765289731835167\n",
      "Copying gs://qwiklabs-asl-03-4fafb71c2045_cloudbuild/source/1765289731.607243-9a47ab0d40b14510ba3d1ed1a907cefe.tgz#1765289731835167...\n",
      "/ [1 files][ 61.0 KiB/ 61.0 KiB]                                                \n",
      "Operation completed over 1 objects/61.0 KiB.\n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: latest: Pulling from qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app\n",
      "Step #0: 8cd46d290033: Pulling fs layer\n",
      "Step #0: 2e6afa3f266c: Pulling fs layer\n",
      "Step #0: 2e66a70da0be: Pulling fs layer\n",
      "Step #0: 1c8ff076d818: Pulling fs layer\n",
      "Step #0: 35c32d99ea0a: Pulling fs layer\n",
      "Step #0: a096358acc3d: Pulling fs layer\n",
      "Step #0: 62fcc761cda6: Pulling fs layer\n",
      "Step #0: 8cfecd7fda2f: Pulling fs layer\n",
      "Step #0: cd6eeee39c7d: Pulling fs layer\n",
      "Step #0: ed009193a63c: Pulling fs layer\n",
      "Step #0: cc7a9fa69b04: Pulling fs layer\n",
      "Step #0: b4386cf584b8: Pulling fs layer\n",
      "Step #0: e18ac31791ed: Pulling fs layer\n",
      "Step #0: 62fcc761cda6: Waiting\n",
      "Step #0: 8cfecd7fda2f: Waiting\n",
      "Step #0: cd6eeee39c7d: Waiting\n",
      "Step #0: ed009193a63c: Waiting\n",
      "Step #0: cc7a9fa69b04: Waiting\n",
      "Step #0: b4386cf584b8: Waiting\n",
      "Step #0: e18ac31791ed: Waiting\n",
      "Step #0: 35c32d99ea0a: Verifying Checksum\n",
      "Step #0: 35c32d99ea0a: Download complete\n",
      "Step #0: 62fcc761cda6: Download complete\n",
      "Step #0: a096358acc3d: Download complete\n",
      "Step #0: cd6eeee39c7d: Verifying Checksum\n",
      "Step #0: cd6eeee39c7d: Download complete\n",
      "Step #0: 2e6afa3f266c: Verifying Checksum\n",
      "Step #0: 2e6afa3f266c: Download complete\n",
      "Step #0: ed009193a63c: Verifying Checksum\n",
      "Step #0: ed009193a63c: Download complete\n",
      "Step #0: 8cd46d290033: Verifying Checksum\n",
      "Step #0: 8cd46d290033: Download complete\n",
      "Step #0: 8cfecd7fda2f: Download complete\n",
      "Step #0: e18ac31791ed: Verifying Checksum\n",
      "Step #0: e18ac31791ed: Download complete\n",
      "Step #0: b4386cf584b8: Verifying Checksum\n",
      "Step #0: b4386cf584b8: Download complete\n",
      "Step #0: 2e66a70da0be: Verifying Checksum\n",
      "Step #0: 2e66a70da0be: Download complete\n",
      "Step #0: 1c8ff076d818: Verifying Checksum\n",
      "Step #0: 1c8ff076d818: Download complete\n",
      "Step #0: cc7a9fa69b04: Verifying Checksum\n",
      "Step #0: cc7a9fa69b04: Download complete\n",
      "Step #0: 8cd46d290033: Pull complete\n",
      "Step #0: 2e6afa3f266c: Pull complete\n",
      "Step #0: 2e66a70da0be: Pull complete\n",
      "Step #0: 1c8ff076d818: Pull complete\n",
      "Step #0: 35c32d99ea0a: Pull complete\n",
      "Step #0: a096358acc3d: Pull complete\n",
      "Step #0: 62fcc761cda6: Pull complete\n",
      "Step #0: 8cfecd7fda2f: Pull complete\n",
      "Step #0: cd6eeee39c7d: Pull complete\n",
      "Step #0: ed009193a63c: Pull complete\n",
      "Step #0: cc7a9fa69b04: Pull complete\n",
      "Step #0: b4386cf584b8: Pull complete\n",
      "Step #0: e18ac31791ed: Pull complete\n",
      "Step #0: Digest: sha256:7965c58e9b9c064ad7bddccb184bff8f62a61e7ec2bc31e7a603f0a035e9dc7c\n",
      "Step #0: Status: Downloaded newer image for us-central1-docker.pkg.dev/qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app:latest\n",
      "Step #0: us-central1-docker.pkg.dev/qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app:latest\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1: Sending build context to Docker daemon  138.8kB\n",
      "Step #1: Step 1/8 : FROM python:3.10.14\n",
      "Step #1: 3.10.14: Pulling from library/python\n",
      "Step #1: 8cd46d290033: Already exists\n",
      "Step #1: 2e6afa3f266c: Already exists\n",
      "Step #1: 2e66a70da0be: Already exists\n",
      "Step #1: 1c8ff076d818: Already exists\n",
      "Step #1: 35c32d99ea0a: Already exists\n",
      "Step #1: a096358acc3d: Already exists\n",
      "Step #1: 62fcc761cda6: Already exists\n",
      "Step #1: 8cfecd7fda2f: Already exists\n",
      "Step #1: Digest: sha256:9c0e621579faf384d982986f2e0ba86bf09619076842cd0fbd2f24a3bf09f0bc\n",
      "Step #1: Status: Downloaded newer image for python:3.10.14\n",
      "Step #1:  ---> bca130f2ff80\n",
      "Step #1: Step 2/8 : WORKDIR /app\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 7512db9213d3\n",
      "Step #1: Step 3/8 : COPY requirements.txt /app\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 03b7d59aae6c\n",
      "Step #1: Step 4/8 : RUN pip install -r requirements.txt\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 34f8dc33b4bd\n",
      "Step #1: Step 5/8 : COPY assets /app/assets\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 01ddeaf9bce7\n",
      "Step #1: Step 6/8 : COPY app.py /app\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 610ddbf26683\n",
      "Step #1: Step 7/8 : EXPOSE 8080\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 330f79108a78\n",
      "Step #1: Step 8/8 : CMD streamlit run --server.port 8080 --server.enableCORS false app.py\n",
      "Step #1:  ---> Using cache\n",
      "Step #1:  ---> 030524367e95\n",
      "Step #1: Successfully built 030524367e95\n",
      "Step #1: Successfully tagged us-central1-docker.pkg.dev/qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app:latest\n",
      "Finished Step #1\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app:latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app]\n",
      "b52d9e2679e1: Preparing\n",
      "baf5be02437d: Preparing\n",
      "95d0753a96f5: Preparing\n",
      "7e2fcb213fa9: Preparing\n",
      "dbdbc63fbc4a: Preparing\n",
      "80a8aad426ce: Preparing\n",
      "9212a53d028a: Preparing\n",
      "0df5b6dad565: Preparing\n",
      "1d3a54010123: Preparing\n",
      "3a8081ce85fa: Preparing\n",
      "045d8b74bf0d: Preparing\n",
      "25879f85bbb0: Preparing\n",
      "6abe10f2f601: Preparing\n",
      "045d8b74bf0d: Waiting\n",
      "25879f85bbb0: Waiting\n",
      "6abe10f2f601: Waiting\n",
      "7e2fcb213fa9: Layer already exists\n",
      "3a8081ce85fa: Layer already exists\n",
      "80a8aad426ce: Layer already exists\n",
      "b52d9e2679e1: Layer already exists\n",
      "dbdbc63fbc4a: Layer already exists\n",
      "95d0753a96f5: Layer already exists\n",
      "0df5b6dad565: Layer already exists\n",
      "baf5be02437d: Layer already exists\n",
      "1d3a54010123: Layer already exists\n",
      "9212a53d028a: Layer already exists\n",
      "045d8b74bf0d: Layer already exists\n",
      "25879f85bbb0: Layer already exists\n",
      "6abe10f2f601: Layer already exists\n",
      "latest: digest: sha256:7965c58e9b9c064ad7bddccb184bff8f62a61e7ec2bc31e7a603f0a035e9dc7c size: 3052\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                                                    STATUS\n",
      "7c130f52-c7c9-4b67-b07c-bab24c4158c5  2025-12-09T14:15:31+00:00  50S       gs://qwiklabs-asl-03-4fafb71c2045_cloudbuild/source/1765289731.607243-9a47ab0d40b14510ba3d1ed1a907cefe.tgz  us-central1-docker.pkg.dev/qwiklabs-asl-03-4fafb71c2045/gemini-chatbot-app/app (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --config cloudbuild.yaml --region $REGION . --substitutions _CONTAINER_PATH={CONTAINER_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212e426-57d5-4f5b-93a4-4295344cf0b9",
   "metadata": {},
   "source": [
    "### Deploying to Cloud Run\n",
    "With our container image stored in Artifact Registry is ready, we're all set to deploy our Streamlit app to Cloud Run.\n",
    "\n",
    "You can also consider incorporating this command into the `cloudbuild.yaml` we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90a852ea-cc32-4a63-8838-e97ba4b8bbd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:16:25.016915Z",
     "iopub.status.busy": "2025-12-09T14:16:25.016093Z",
     "iopub.status.idle": "2025-12-09T14:16:25.024435Z",
     "shell.execute_reply": "2025-12-09T14:16:25.022544Z",
     "shell.execute_reply.started": "2025-12-09T14:16:25.016786Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"gemini-chatbot-app\"\n",
    "os.environ[\"APP_NAME\"] = APP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cb64fe98-c1d4-4454-b1b8-f3a6800e4b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:16:25.028206Z",
     "iopub.status.busy": "2025-12-09T14:16:25.027776Z",
     "iopub.status.idle": "2025-12-09T14:16:36.573037Z",
     "shell.execute_reply": "2025-12-09T14:16:36.571327Z",
     "shell.execute_reply.started": "2025-12-09T14:16:25.028167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying the application to Cloud Run with Agent API URL...\n",
      "Deployment Done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Substitua [SEU_URL_ADK_AQUI] pelo endereço real do seu agente ADK no Cloud Run.\n",
    "AGENT_URL='https://adk-demo-agent-crv3-949926840523.us-central1.run.app'\n",
    "\n",
    "echo 'Deploying the application to Cloud Run with Agent API URL...'\n",
    "gcloud run deploy $APP_NAME \\\n",
    "  --image $CONTAINER_PATH:latest --min-instances 1 --max-instances 1 --cpu 1 \\\n",
    "  --memory 4Gi --region us-central1 \\\n",
    "  --allow-unauthenticated \\\n",
    "  --update-env-vars AGENT_API_ENDPOINT=$AGENT_URL > /dev/null 2>&1 && \\\n",
    "echo 'Deployment Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf51f5-6703-4a7f-aebc-ac32dfda24eb",
   "metadata": {},
   "source": [
    "### Connect to Cloud Run app via Cloud Shell\n",
    "\n",
    "\n",
    "You have a lot of flexibility when it comes to configuring access to your Cloud Run service. You can even [make it publicly accessible](https://cloud.google.com/run/docs/authenticating/public) if you want to.\n",
    "\n",
    "However, for this example, let's see how to connect to your Cloud Run app securely from Cloud Shell using a proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9840eb6-5f47-45b3-a156-e7b96849d97e",
   "metadata": {},
   "source": [
    "Follow these steps to open the app from Cloud Shell.\n",
    "1. Run the next cell, copy the output `gcloud run services proxy ...`command.\n",
    "2. Open Cloud Shell, paste and run the command.\n",
    "3. In Cloud Shell, click the \"Web Preview\" button on the toolbar.\n",
    "4. Select \"Preview on port 8080\"\n",
    "5. A new browser tab or window will open, displaying your Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9c57754f-c055-4cb4-8175-338336e5bfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T14:16:36.575657Z",
     "iopub.status.busy": "2025-12-09T14:16:36.574577Z",
     "iopub.status.idle": "2025-12-09T14:16:36.581603Z",
     "shell.execute_reply": "2025-12-09T14:16:36.580123Z",
     "shell.execute_reply.started": "2025-12-09T14:16:36.575613Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcloud run services proxy gemini-chatbot-app --project qwiklabs-asl-03-4fafb71c2045 --region us-central1\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"gcloud run services proxy {APP_NAME} --project {PROJECT} --region {REGION}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9501082-c0b3-46ab-b55f-b825f41dacf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try the app\n",
    "Now you're ready to test your app.\n",
    "\n",
    "Enjoy conversations with Gemini!\n",
    "\n",
    "<img width=\"600\" alt=\"image\" src=\"https://github.com/user-attachments/assets/08a6421a-3b50-413d-a921-55476b03b1ec\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcef05-35c8-4d1a-bb4b-4217c1a84020",
   "metadata": {},
   "source": [
    "Copyright 2024 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
